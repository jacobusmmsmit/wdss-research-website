<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Higher or Lower: Reinventing a Classic Card Game</title>
      <link href="/higher-or-lower/"/>
      <url>/higher-or-lower/</url>
      
        <content type="html"><![CDATA[<div class="note info"><p>This post is the corresponding write-up for a WDSS project in which a small team of society members collaborated to produce a web-toy that plays a game of Higher or Lower using the Twitter follower counts of celebrities. You can play this game at <a href="https://shiny.warwickdatascience.com/higher-or-lower/" target="_blank" rel="noopener">this link</a>.</p></div><h2 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h2><p>Sometimes, simplicity is beautiful. Higher or Lower is a game embodying this philosophy. Played solo with a standard deck of cards, play consists of revealing these one at a time after first guessing whether the next card will have a higher or lower value. In recent years, this game has been re-envisioned as a <a href="http://www.higherlowergame.com/" target="_blank" rel="noopener">popular web toy</a>, in which card values are replaced by the number of global monthly Google searches for various topics. Not wishing to limit ourselves to search results, we decided to implement our own online version of the classic game based on the follower counts of Twitter celebrities. The final app can be found at the link above, and we will spend the rest of this post looking into the techniques behind our approach as well as reviewing the lessons this project can teach us about collaborative data science at WDSS.</p><p>For our purposes, this project is an ideal medium to practise web scraping and creating sharable products for others to enjoy. Web scraping is a way of extracting data from websites, leveraging automation to gather information efficiently and without unnecessary repetition. In all, three members of WDSS worked on this project, combining their specific skills to develop the final product. <a href="https://www.linkedin.com/in/tim-hargreaves/" target="_blank" rel="noopener">Tim Hargreaves</a>, focused on the backbone of the app, <a href="https://www.linkedin.com/in/mhbardsley/" target="_blank" rel="noopener">Matthew Bardsley</a>, the visuals of the game, and I (<a href="https://www.linkedin.com/in/parthdevalia/" target="_blank" rel="noopener">Parth Devalia</a>) have responsibility for the communication of results.</p><h2 id="implemenation"><a class="markdownIt-Anchor" href="#implemenation"></a> Implemenation</h2><div class="note info"><p>The source code for the web app and scraping scripts have been open-sourced in <a href="https://github.com/warwickdatascience/higher-or-lower" target="_blank" rel="noopener">this repository</a>.</p></div><p>With 330 million monthly users, Twitter has become an indispensable medium for instant news and opinions from politicians, brands, and of course, celebrities. Manually defining celebrityhood and iterating through matching accounts would be a difficult task, so we decided to look at what existing resources we could take advantage of. We eventually settled on a website called <a href="http://profilerehab.com/twitter-help/celebrity_twitter_list" target="_blank" rel="noopener">ProfileRehab</a>. On this site, links to celebrities’ Twitter accounts are sorted into categories. By scraping this information we were able to collect Twitter profile URLs for around five hundred celebrities, matched to their names. We then interfaced with the Twitter API to read their respective follower counts and download their profile pictures. This entire scraping process was performed using Python, to take advantage of the rich ecosystem of web scraping packages the language has.</p><p>You may well be asking, “What is an API?”, and so I will take a moment to introduce this term. Application Programming Interfaces (APIs) simply allow applications to communicate with each other and are responsible for much of the connectivity we rely upon. They act as messengers, taking your request, telling the target application what you want to do, and then returning the response. Rather than accessing the application server directly, APIs offer us a dedicated access point, improving security and reliability. A common analogy is that of a restaurant—the API is the waiter, the interface between your table and the kitchen, taking your request and returning the response (the food).</p><p>With regard to our project, we decided to access the data we wanted through an API as Twitter have made recent obfuscations to their website code to make direct scraping more difficult. Use of Twitter’s API, as is often the case, is subject to terms and conditions regarding the usage of the data obtained. Additionally, the company have implemented a rate limit; that is, a maximum number of requests they can handle in a given timespan (just like with a restaurant waiter). Careful examination of these limitations needs to be considered when using an API, but fortunately we found them to be adequate for our needs.</p><p>The application is made using Shiny, a package for the R programming language that allows you to build interactive web applications. The framework allows for the development of powerful and flexible web applications with no need for HTML, CSS or JavaScript knowledge. For this reason, Shiny stands out for its unrivalled speed of development.</p><p>Despite its benefits, the raw product of Shiny development is not always the prettiest and can lack strong mobile support. To overcome this, Matthew implemented additional styling using CSS to improve the aesthetics of the final application.</p><h2 id="takeaways"><a class="markdownIt-Anchor" href="#takeaways"></a> Takeaways</h2><p>This project allowed us three WDSS members to work together in creating something that we wouldn’t have done individually. Further, if not for the society, we would not have had the opportunity to work together. This highlights the role of WDSS, bringing people from different backgrounds together to solve challenging problems.</p><p>Projects are extremely important in growing your skills and are critical for developing a strong portfolio. Through collaboration, we can see problems from new perspectives, build our professional networks, and gain experience of working in a team. This is in comparison to university work, that is often done alone without using real world data, and usually without a solid final product.</p><p>This project leverages infrastructure offered by WDSS, such as our blogging platform and Shiny server. For this reason, alongside the support<br>offered by experienced students, working with WDSS to complete research makes it easier to get projects off the ground and showcase what you can do.</p><p>Thank you for reading and we hope you enjoy playing our implementation of Higher or Lower.</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shiny </tag>
            
            <tag> web-scraping </tag>
            
            <tag> game </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Urban Cities: A History Told By Data</title>
      <link href="/urban-cities/"/>
      <url>/urban-cities/</url>
      
        <content type="html"><![CDATA[<div class="note info"><p><strong>Accessing Post Source</strong></p><p>We are still working on getting this site set up, so source code for this post is not yet available. Check back soon and you’ll be able to find it linked here.</p></div><h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2><p><img src="/" class="lazyload" data-src="/images/urban-cities/barcelona.jpg"  alt="The skyline of Barcelona"><br>An aerial observer would be forgiven for mistaking Barcelona’s octagonal blocks and diagonal streets as some red-brick reimagining of Legoland. Indeed, Spain’s 2000-year-old capital is a strict grid-like design, engineered to tackle overpopulation while maximizing airflow for its inhabitants. It’s an ancient city with all the efficiency of contemporary urban structures like New York.</p><p>Barcelona is a fascinating example, but its grid-like patterns are obvious to the human eye. I wondered about other cities with more complex features. What subtle quirks lie in the road/street structures of Bristol, Newcastle or Coventry?</p><p>For that question I wanted a scientific answer, so I set about applying data science to learn more about the intricacies of the UK’s densely populated cities.</p><h3 id="methodology"><a class="markdownIt-Anchor" href="#methodology"></a> Methodology</h3><p>This project was made possible by <a href="https://www.openstreetmap.org/" target="_blank" rel="noopener">OpenStreetMap</a> (OSM). OSM is a world-wide database of roads, trails and streets, verified by field maps and aerial imagery and maintained by an active community of engineers and GIS professionals. Its open API enables raw geodata to be sourced on any city in the world.</p><p>OSM describes geodata elements in a number of ways. Linear features, like roads or rivers, are modelled using a “way”: nodes (between 2 and 2000) connected into a simple chain of line segments, a polyline. Most whole cities with solid polygon geometries (Manchester and Birmingham to name a few) are bounded by a single “closed way”, with the same start and end nodes. These are generally those with a well-defined natural border in the real world. Others, that have no obvious boundary, are rather represented as a single point marker, denoting the center of the city. We will be focusing on the former type as the more complex definition of the geometry allows us to draw far more insight.</p><p>Of the UK cities with these ‘nice’ geometries, the twelve with the largest populations were considered and OSM API was used to fetch full network graphs, from which the bearings of streets were determined. A summary of this data is shown below.</p><table><thead><tr><th></th><th>geometry</th><th>place_name</th><th>bbox_north</th><th>bbox_south</th><th>bbox_east</th><th>bbox_west</th></tr></thead><tbody><tr><th>0</th><td>POLYGON ((-2.03365 52.40231, -2.03322 52.40217...</td><td>Birmingham, West Midlands Combined Authority, ...</td><td>52.608706</td><td>52.381053</td><td>-1.728858</td><td>-2.033649</td></tr><tr><th>1</th><td>POLYGON ((-1.80042 53.88595, -1.80041 53.88594...</td><td>Leeds, Yorkshire and the Humber, England, Unit...</td><td>53.945872</td><td>53.698968</td><td>-1.290352</td><td>-1.800421</td></tr><tr><th>2</th><td>POLYGON ((-1.80147 53.48098, -1.80049 53.48027...</td><td>Sheffield, Yorkshire and the Humber, England, ...</td><td>53.503104</td><td>53.304512</td><td>-1.324669</td><td>-1.801471</td></tr><tr><th>3</th><td>POLYGON ((-2.06125 53.82562, -2.06017 53.82504...</td><td>Bradford, Yorkshire and the Humber, England, U...</td><td>53.963151</td><td>53.724341</td><td>-1.640330</td><td>-2.061248</td></tr><tr><th>4</th><td>POLYGON ((-2.31992 53.41161, -2.31847 53.40999...</td><td>Manchester, Greater Manchester, North West Eng...</td><td>53.544592</td><td>53.340104</td><td>-2.146829</td><td>-2.319918</td></tr><tr><th>5</th><td>POLYGON ((-3.01917 53.43616, -3.01806 53.43323...</td><td>Liverpool, North West England, England, United...</td><td>53.474967</td><td>53.311543</td><td>-2.818000</td><td>-3.019173</td></tr><tr><th>6</th><td>POLYGON ((-2.71837 51.50617, -2.71837 51.50616...</td><td>Bristol, City of Bristol, South West England, ...</td><td>51.544432</td><td>51.397284</td><td>-2.510419</td><td>-2.718370</td></tr><tr><th>7</th><td>POLYGON ((-1.62490 53.65363, -1.62488 53.65358...</td><td>Wakefield, Yorkshire and the Humber, England, ...</td><td>53.741811</td><td>53.575349</td><td>-1.198814</td><td>-1.624898</td></tr><tr><th>8</th><td>POLYGON ((-1.61446 52.42795, -1.61412 52.42774...</td><td>Coventry, West Midlands Combined Authority, We...</td><td>52.464772</td><td>52.363885</td><td>-1.423957</td><td>-1.614459</td></tr><tr><th>9</th><td>POLYGON ((-1.24696 52.95344, -1.24689 52.95317...</td><td>City of Nottingham, East Midlands, England, Un...</td><td>53.018672</td><td>52.889008</td><td>-1.086119</td><td>-1.246956</td></tr><tr><th>10</th><td>POLYGON ((-1.77567 54.98962, -1.77566 54.98955...</td><td>Newcastle upon Tyne, Tyne and Wear, North East...</td><td>55.079382</td><td>54.959032</td><td>-1.529200</td><td>-1.775672</td></tr><tr><th>11</th><td>POLYGON ((-1.56888 54.92462, -1.56824 54.92409...</td><td>Sunderland, Tyne and Wear, North East England,...</td><td>54.944170</td><td>54.799042</td><td>-1.345665</td><td>-1.568879</td></tr></tbody></table><h2 id="visualizations"><a class="markdownIt-Anchor" href="#visualizations"></a> Visualizations</h2><p>For each of these 12 cities, the returned bearings were weighted by street length to produce the following visualisations using simple polar projection plots. It is important to note two key points about this approach:</p><ol><li>The bearings of streets were derived from only their start and finish nodes, ignoring paths in-between. This was to ensure reasonable computation times as an alternative to using the full polylines.</li><li>Naturally, bearings are rotationally symmetric as we do not account for the direction of one-way streets.</li></ol><h3 id="birmingham"><a class="markdownIt-Anchor" href="#birmingham"></a> Birmingham</h3><p><img src="/" class="lazyload" data-src="/images/urban-cities/urban-cities_11_0.png"  alt=""></p><p>Birmingham’s visualization is unmistakably circular. Many older cities lack a grid structure, with impromptu-built streets going off in many different directions. The place now called “Birmingham” has been around for more than 1,400 years. It was believed to have been established by a Saxon tribe, before expanding over the centuries into the city of 8500 streets we know today.</p><p><img src="/" class="lazyload" data-src="/images/urban-cities/prospect_of_birmingham.jpg"  alt="William Westley's 1732 Prospect of Birmingham"></p><h3 id="manchester-newcastle"><a class="markdownIt-Anchor" href="#manchester-newcastle"></a> Manchester &amp; Newcastle</h3><p><img src="/" class="lazyload" data-src="/images/urban-cities/urban-cities_15_0.png"  alt=""></p><p>Manchester displays quite a clear cross-like visualization. This city has an interesting grid structure with a strong emphasis on moving north-to-south. The east-to-west flow is perhaps due to Manchester sitting almost directly between Liverpool and Sheffield, and the reduced SE/NW activity might result from its position just in the upper left of the Peak District.</p><p>Newcastle is similar but for a more obvious reason; its central ring-road system, which is vaguely hexagonal, is presumably responsible for the high degree of symmetry we observe.</p><h3 id="coventry"><a class="markdownIt-Anchor" href="#coventry"></a> Coventry</h3><p><img src="/" class="lazyload" data-src="/images/urban-cities/urban-cities_18_0.png"  alt=""></p><p>Not unlike Manchester, Coventry’s visualization hints at a grid-like design. Famously, this ancient city—once a hotspot of trade for cloth and textiles—was obliterated in 1940 by a series of bombing raids, now called the Coventry Blitz. In the decades following, the city’s remains were rebuilt into a modern grid structure.</p><h3 id="bristol"><a class="markdownIt-Anchor" href="#bristol"></a> Bristol</h3><p><img src="/" class="lazyload" data-src="/images/urban-cities/urban-cities_21_0.png"  alt=""></p><p>For a city founded on the turn of the second-last millennia, we wouldn’t expect to see much beyond a uniformly distributed set of bearings. Yet Bristol’s otherwise almost-circular plot is cut along the NE/SW line. Modern Bristol is dominated by the M5, as well as the River Avon. It’s interesting that a 1960s motorway construction can have such an impact on the bearings of an ancient city.</p><h2 id="final-thoughts"><a class="markdownIt-Anchor" href="#final-thoughts"></a> Final Thoughts</h2><p>As well as analyzing the street orientations of individual cities, it is beneficial to to showcase their visualizations side-by-side to draw comparisons and appreciate relative differences. To extend, I have collated the visualizations for the twelve cities I considered into one final image.</p><p><img src="/" class="lazyload" data-src="/images/urban-cities/urban-cities_25_0.png"  alt=""></p><h3 id="the-importance-of-data-science"><a class="markdownIt-Anchor" href="#the-importance-of-data-science"></a> The Importance of Data Science</h3><p>I think it important to observe how data science, once a niche and theoretical discipline, can offer such rich insights into the history of the UK’s major cities. From Birmingham’s pre-industrial beginnings, to the devastating campaigns of the German Luftwaffe, these simple visualisations tell stories of our past. They compress a millennia-long archive of the achievements and failures that gave rise to modern Britain.</p><p>To that extent, if you are a data scientist wondering how you can apply your technical skills to real-world projects, or a student with domain expertise, keen to build up the technical skills to answer the questions you care about, make sure you follow Warwick Data Science Society <a href="https://www.facebook.com/warwickdatascience" target="_blank" rel="noopener">on social media</a> to keep up-to-date with relevant opportunties. These include academic talks, data science news, workshops, and beginners programming courses, so there is certainly something for everyone. Thank you for reading this piece.</p>]]></content>
      
      
      <categories>
          
          <category> Humanities </category>
          
          <category> Geography </category>
          
          <category> History </category>
          
      </categories>
      
      
        <tags>
            
            <tag> visualization </tag>
            
            <tag> data-analysis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>What Factors Actually Affect Your Grades?</title>
      <link href="/school-success/"/>
      <url>/school-success/</url>
      
        <content type="html"><![CDATA[<div class="note info"><p><strong>Accessing Post Source</strong><br>We are still working on getting this site set up, so source code for this post is not yet available. Check back soon and you’ll be able to find it linked here.</p></div><p>With exam period approaching fast, every student is wondering how to score the best possible grade. Some factors—like how much sleep you’re getting or how healthy you are—seem to have an obvious correlation with your final grade. What about your relationship status? How much should you be studying to achieve the grade you want? Does the subject you’re studying influence your final grade? In this article, we will use two datasets containing student math and Portuguese language performance in two different Portuguese schools and see which factors affected student performance the most.</p><h2 id="exploratory-data-analysis"><a class="markdownIt-Anchor" href="#exploratory-data-analysis"></a> Exploratory Data Analysis</h2><h3 id="dataset-overview"><a class="markdownIt-Anchor" href="#dataset-overview"></a> Dataset Overview</h3><p>The variables are the same for the two datasets:</p><table><thead><tr><th style="text-align:center">Variable</th><th style="text-align:center">Description</th><th style="text-align:center">Type</th><th style="text-align:center">Possible Values</th></tr></thead><tbody><tr><td style="text-align:center">school</td><td style="text-align:center">School</td><td style="text-align:center">binary</td><td style="text-align:center">GP—Gabriel Pereira; MS—Mousinho da Silveira</td></tr><tr><td style="text-align:center">sex</td><td style="text-align:center">Sex</td><td style="text-align:center">binary</td><td style="text-align:center">F—female; M—male</td></tr><tr><td style="text-align:center">age</td><td style="text-align:center">Age</td><td style="text-align:center">numeric</td><td style="text-align:center">15–22, inclusive</td></tr><tr><td style="text-align:center">address</td><td style="text-align:center">Address type</td><td style="text-align:center">binary</td><td style="text-align:center">U—Urban; R—Rural</td></tr><tr><td style="text-align:center">famsize</td><td style="text-align:center">Family Size</td><td style="text-align:center">binary</td><td style="text-align:center">LE3—less than or equal to 3; GE3—greater than 3</td></tr><tr><td style="text-align:center">Pstatus</td><td style="text-align:center">Parent’s cohabitation status</td><td style="text-align:center">binary</td><td style="text-align:center">T—living together; A—living apart</td></tr><tr><td style="text-align:center">Medu</td><td style="text-align:center">Mother’s Education</td><td style="text-align:center">ordinal</td><td style="text-align:center">0—none; 1—up to 4th grade; 2—5th–9th grade; 3—secondary; 4—higher</td></tr><tr><td style="text-align:center">Fedu</td><td style="text-align:center">Father’s Education</td><td style="text-align:center">ordinal</td><td style="text-align:center">0—none; 1—up to 4th grade; 2—5th–9th grade; 3—secondary; 4—higher</td></tr><tr><td style="text-align:center">Mjob</td><td style="text-align:center">Mother’s Job</td><td style="text-align:center">nominal</td><td style="text-align:center">teacher; health(-care related); (civil )services; at home; other</td></tr><tr><td style="text-align:center">Fjob</td><td style="text-align:center">Father’s Job</td><td style="text-align:center">nominal</td><td style="text-align:center">teacher; health(-care related); (civil )services; at home; other</td></tr><tr><td style="text-align:center">reason</td><td style="text-align:center">Reason for choosing school</td><td style="text-align:center">nominal</td><td style="text-align:center">(close to )home; (school )reputation; course(preference); other</td></tr><tr><td style="text-align:center">guardian</td><td style="text-align:center">Student’s guardian</td><td style="text-align:center">nominal</td><td style="text-align:center">mother; father; other</td></tr><tr><td style="text-align:center">traveltime</td><td style="text-align:center">Travel time to school</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—&lt;15 min.; 2—15–30 min.; 3—30 min.–1 hour; 4—&gt;1 hour</td></tr><tr><td style="text-align:center">studytime</td><td style="text-align:center">Weekly study time</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—&lt;2 hours; 2—2–5 hours; 3—5–10 hours; 4—&gt;10 hours</td></tr><tr><td style="text-align:center">failures</td><td style="text-align:center">Past class failures</td><td style="text-align:center">numeric</td><td style="text-align:center">0–3, else 4</td></tr><tr><td style="text-align:center">schoolsup</td><td style="text-align:center">Extra educational support</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">famsup</td><td style="text-align:center">Family educational support</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">paid</td><td style="text-align:center">Extra paid classes</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">activities</td><td style="text-align:center">Extra-curricular activities</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">nursery</td><td style="text-align:center">Attend nursery</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">higher</td><td style="text-align:center">Wants to take higher education</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">internet</td><td style="text-align:center">Home internet access</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">romantic</td><td style="text-align:center">In a romantic relationship</td><td style="text-align:center">binary</td><td style="text-align:center">yes; no</td></tr><tr><td style="text-align:center">famrel</td><td style="text-align:center">Quality of family relationships</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—very bad to 5—very good</td></tr><tr><td style="text-align:center">freetime</td><td style="text-align:center">Free time after school</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—very low to 5—very high</td></tr><tr><td style="text-align:center">goout</td><td style="text-align:center">Going out with friends</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—very low to 5—very high</td></tr><tr><td style="text-align:center">Dalc</td><td style="text-align:center">Workday alcohol consumption</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—very low to 5—very high</td></tr><tr><td style="text-align:center">Walc</td><td style="text-align:center">Weekend alcohol consumption</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—very low to 5—very high</td></tr><tr><td style="text-align:center">health</td><td style="text-align:center">Current health status</td><td style="text-align:center">ordinal</td><td style="text-align:center">1—very bad to 5—very good</td></tr><tr><td style="text-align:center">absences</td><td style="text-align:center">Number absences</td><td style="text-align:center">numeric</td><td style="text-align:center">0–93</td></tr><tr><td style="text-align:center">G1</td><td style="text-align:center">First Period Grade</td><td style="text-align:center">numeric</td><td style="text-align:center">0–20</td></tr><tr><td style="text-align:center">G2</td><td style="text-align:center">Second Period Grade</td><td style="text-align:center">numeric</td><td style="text-align:center">0–20</td></tr><tr><td style="text-align:center">G3</td><td style="text-align:center">Final Grade</td><td style="text-align:center">numeric</td><td style="text-align:center">0–20</td></tr></tbody></table><p>I will be conducting a basic analysis of the dataset followed by visualizations of the correlations between different factors. Finally, I will build a linear regression model for each subject to predict the students’ final grades.</p><p>We will start by importing all the necessary packages and load the datasets into a pandas dataframe.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import necessary packages</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> statistics <span class="keyword">as</span> stats</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the dataset from the csv file using pandas</span></span><br><span class="line">data_m = pd.read_csv(<span class="string">r'data/student-mat.csv'</span>, sep=<span class="string">';'</span>)</span><br><span class="line">data_p = pd.read_csv(<span class="string">r'data/student-por.csv'</span>, sep=<span class="string">';'</span>)</span><br></pre></td></tr></table></figure><p>We can start by taking a look at the first few rows of each dataset.</p><pre><code>First 5 lines of the math performance dataset:</code></pre><table><thead><tr><th></th><th>school</th><th>sex</th><th>age</th><th>address</th><th>famsize</th><th>Pstatus</th><th>Medu</th><th>Fedu</th><th>Mjob</th><th>Fjob</th><th>reason</th><th>guardian</th><th>traveltime</th><th>studytime</th><th>failures</th><th>schoolsup</th><th>famsup</th><th>paid</th><th>activities</th><th>nursery</th><th>higher</th><th>internet</th><th>romantic</th><th>famrel</th><th>freetime</th><th>goout</th><th>Dalc</th><th>Walc</th><th>health</th><th>absences</th><th>G1</th><th>G2</th><th>G3</th></tr></thead><tbody><tr><th>0</th><td>GP</td><td>F</td><td>18</td><td>U</td><td>GT3</td><td>A</td><td>4</td><td>4</td><td>at_home</td><td>teacher</td><td>course</td><td>mother</td><td>2</td><td>2</td><td>0</td><td>yes</td><td>no</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>no</td><td>4</td><td>3</td><td>4</td><td>1</td><td>1</td><td>3</td><td>6</td><td>5</td><td>6</td><td>6</td></tr><tr><th>1</th><td>GP</td><td>F</td><td>17</td><td>U</td><td>GT3</td><td>T</td><td>1</td><td>1</td><td>at_home</td><td>other</td><td>course</td><td>father</td><td>1</td><td>2</td><td>0</td><td>no</td><td>yes</td><td>no</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>5</td><td>3</td><td>3</td><td>1</td><td>1</td><td>3</td><td>4</td><td>5</td><td>5</td><td>6</td></tr><tr><th>2</th><td>GP</td><td>F</td><td>15</td><td>U</td><td>LE3</td><td>T</td><td>1</td><td>1</td><td>at_home</td><td>other</td><td>other</td><td>mother</td><td>1</td><td>2</td><td>3</td><td>yes</td><td>no</td><td>yes</td><td>no</td><td>yes</td><td>yes</td><td>yes</td><td>no</td><td>4</td><td>3</td><td>2</td><td>2</td><td>3</td><td>3</td><td>10</td><td>7</td><td>8</td><td>10</td></tr><tr><th>3</th><td>GP</td><td>F</td><td>15</td><td>U</td><td>GT3</td><td>T</td><td>4</td><td>2</td><td>health</td><td>services</td><td>home</td><td>mother</td><td>1</td><td>3</td><td>0</td><td>no</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>3</td><td>2</td><td>2</td><td>1</td><td>1</td><td>5</td><td>2</td><td>15</td><td>14</td><td>15</td></tr><tr><th>4</th><td>GP</td><td>F</td><td>16</td><td>U</td><td>GT3</td><td>T</td><td>3</td><td>3</td><td>other</td><td>other</td><td>home</td><td>father</td><td>1</td><td>2</td><td>0</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>no</td><td>4</td><td>3</td><td>2</td><td>1</td><td>2</td><td>5</td><td>4</td><td>6</td><td>10</td><td>10</td></tr></tbody></table><pre><code>First 5 lines of the Portuguese performance dataset:</code></pre><table><thead><tr><th></th><th>school</th><th>sex</th><th>age</th><th>address</th><th>famsize</th><th>Pstatus</th><th>Medu</th><th>Fedu</th><th>Mjob</th><th>Fjob</th><th>reason</th><th>guardian</th><th>traveltime</th><th>studytime</th><th>failures</th><th>schoolsup</th><th>famsup</th><th>paid</th><th>activities</th><th>nursery</th><th>higher</th><th>internet</th><th>romantic</th><th>famrel</th><th>freetime</th><th>goout</th><th>Dalc</th><th>Walc</th><th>health</th><th>absences</th><th>G1</th><th>G2</th><th>G3</th></tr></thead><tbody><tr><th>0</th><td>GP</td><td>F</td><td>18</td><td>U</td><td>GT3</td><td>A</td><td>4</td><td>4</td><td>at_home</td><td>teacher</td><td>course</td><td>mother</td><td>2</td><td>2</td><td>0</td><td>yes</td><td>no</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>no</td><td>4</td><td>3</td><td>4</td><td>1</td><td>1</td><td>3</td><td>4</td><td>0</td><td>11</td><td>11</td></tr><tr><th>1</th><td>GP</td><td>F</td><td>17</td><td>U</td><td>GT3</td><td>T</td><td>1</td><td>1</td><td>at_home</td><td>other</td><td>course</td><td>father</td><td>1</td><td>2</td><td>0</td><td>no</td><td>yes</td><td>no</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>5</td><td>3</td><td>3</td><td>1</td><td>1</td><td>3</td><td>2</td><td>9</td><td>11</td><td>11</td></tr><tr><th>2</th><td>GP</td><td>F</td><td>15</td><td>U</td><td>LE3</td><td>T</td><td>1</td><td>1</td><td>at_home</td><td>other</td><td>other</td><td>mother</td><td>1</td><td>2</td><td>0</td><td>yes</td><td>no</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>yes</td><td>no</td><td>4</td><td>3</td><td>2</td><td>2</td><td>3</td><td>3</td><td>6</td><td>12</td><td>13</td><td>12</td></tr><tr><th>3</th><td>GP</td><td>F</td><td>15</td><td>U</td><td>GT3</td><td>T</td><td>4</td><td>2</td><td>health</td><td>services</td><td>home</td><td>mother</td><td>1</td><td>3</td><td>0</td><td>no</td><td>yes</td><td>no</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>3</td><td>2</td><td>2</td><td>1</td><td>1</td><td>5</td><td>0</td><td>14</td><td>14</td><td>14</td></tr><tr><th>4</th><td>GP</td><td>F</td><td>16</td><td>U</td><td>GT3</td><td>T</td><td>3</td><td>3</td><td>other</td><td>other</td><td>home</td><td>father</td><td>1</td><td>2</td><td>0</td><td>no</td><td>yes</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>no</td><td>4</td><td>3</td><td>2</td><td>1</td><td>2</td><td>5</td><td>0</td><td>11</td><td>13</td><td>13</td></tr></tbody></table><p>An important detail to note is that there are 395 high school students in the math dataset and 649 in the Portuguese dataset. The grades of the student are from 0 to 20. Furthermore, there are 16 numerical variables out of 33; the rest of the variables will need to be one-hot encoded when we will analyze correlations and build the regression model.</p><p>Now let’s visualize the final grades distributions for both subjects.</p><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_13_0.png"  alt="Distribution of student grades for math and Portuguese"></p><p>We can also calculate that the average final grades for math and Portuguese students are 10.42 and 11.91, respectively. This suggests that Portuguese students score higher on average than math students although this comparison could easily have been skewed by the large number of math students scoring zero.</p><h3 id="finding-and-visualizing-correlations-for-numerical-variables"><a class="markdownIt-Anchor" href="#finding-and-visualizing-correlations-for-numerical-variables"></a> Finding and Visualizing Correlations for Numerical Variables</h3><p>We are now going to automatically find the variables with the strongest correlation to the final grades for both datasets. Finding correlations between non-numeric features and the outcome can get a bit messy, so we will focus on testing only the existing numerical values of the datasets at first. To better visualize the insights, we will also use correlation bar plots and heat maps for both datasets.</p><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_17_0.png"  alt="Correlations between numeric predictors and the response for math"></p><p>To interpret correlation bar plots and heat map:</p><ul><li>The darker the bar/square, the stronger the correlation is.</li><li>Brown represents negative correlations, whereas purple represents positive correlations.</li></ul><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_19_0.png"  alt="Correlations between numeric predictors and the response for Portuguese"></p><p>Insights:</p><ul><li>For both datasets, the number of past classes <code>failures</code> has a strong negative correlation with <code>G3</code>.</li><li>Other common variables with a negative correlation are <code>age</code>, frequency of going out with friends (<code>goout</code>), <code>traveltime</code>, <code>freetime</code> and <code>health</code>.</li><li><code>G1</code> and <code>G2</code> have very strong positive correlation coefficients for both datasets because student performance usually remains constant throughout the year; we will therefore ignore them.</li><li>Other common variables with a positive correlation are: <code>studytime</code>, education of parents (<code>Fedu</code> and <code>Medu</code>) and family relationship (<code>famrel</code>).</li></ul><h3 id="one-hot-encoding"><a class="markdownIt-Anchor" href="#one-hot-encoding"></a> One-Hot Encoding</h3><p>In order to get more insight from these datasets, we need to be able to use the categorical variables as well. An example of categorical variable is the <code>school</code> variable (the student is either at Gabriel Pereira or Mousinho da Silveira) as there are multiple possible values with no intrinsic ordering. We will use a technique called one-hot encoding, which assigns binary value to each category level indicating whether or not that level was the value of the original predictor. Here is an example of how it would look like for the variable father’s job (<code>Fjob</code>).</p><table><thead><tr><th>Father’s Job</th><th style="text-align:center">Occupation_teacher</th><th style="text-align:center">Occupation_health</th><th style="text-align:center">Occupation_services</th><th style="text-align:center">Occupation_at_home</th><th style="text-align:center">Occupation_other</th></tr></thead><tbody><tr><td>teacher</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>health</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>services</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>at_home</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td>other</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr></tbody></table><div class="note warning"><p><strong>Technical Detail</strong><br>One-hot encoding is actually slightly more subtle than the description given above. The missing detail is that we often drop the first of the resulting binary columns. The reason we do this is that knowing the value of the other columns is enough to be certain of the value of the first. Indeed, if all of the other columns are zero, then the first column must be one, and vice-versa. Removing the first column is important as the algebra behind linear regression fails we duplicate predictor information.</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot_encode</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="comment"># Select only categorical variables</span></span><br><span class="line">    cat_df = df.select_dtypes(include=[<span class="string">'object'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># One-hot encode variables</span></span><br><span class="line">    dummy_df = pd.get_dummies(cat_df, drop_first=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Add the response back and return</span></span><br><span class="line">    dummy_df[<span class="string">'G3'</span>] = df[<span class="string">'G3'</span>]</span><br><span class="line">    <span class="keyword">return</span> dummy_df</span><br><span class="line"></span><br><span class="line"><span class="comment"># One-hot encode both datasets</span></span><br><span class="line">dummy_dfm = one_hot_encode(data_m)</span><br><span class="line">dummy_dfp = one_hot_encode(data_p)</span><br></pre></td></tr></table></figure><h3 id="finding-and-visualizing-correlations-for-encoded-categorical-variables"><a class="markdownIt-Anchor" href="#finding-and-visualizing-correlations-for-encoded-categorical-variables"></a> Finding and Visualizing Correlations for Encoded Categorical Variables</h3><p>We can now analyze the correlation coefficients for the final grades of all the variables for both datasets.</p><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_28_0.png"  alt="Correlations between categorical predictors and the response for math"></p><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_29_0.png"  alt="Correlations between categorical predictors and the response for Portuguese"></p><p>Insights:</p><ul><li>Variables that impact negatively final grades in both datasets: in a romantic relationship (<code>romantic_yes</code>), does not want to go to higher education (<code>higher_no</code>), lives in a rural area (<code>address_R</code>) and has no access to internet (<code>internet_no</code>).</li><li>Variables that impact positively final grades in both datasets: not in a romantic relationship (<code>romantic_no</code>), wants to go to higher education (<code>higher_yes</code>), lives in a urban area (<code>address_U</code>), has access to internet (<code>internet_no</code>).</li><li>In Portuguese performance dataset, the <code>school</code> variable has a very high impact on the final grade (negatively impacted if goes to MS and positively impacted if goes to GP).</li><li>Males seem to score higher in math whereas females score higher in portuguese.</li></ul><h2 id="visualizing-key-trends"><a class="markdownIt-Anchor" href="#visualizing-key-trends"></a> Visualizing Key Trends</h2><p>Some of the results are quite unexpected so let’s visualize them.</p><h3 id="effect-of-address-type-on-grades"><a class="markdownIt-Anchor" href="#effect-of-address-type-on-grades"></a> Effect of Address Type on Grades</h3><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_34_0.png"  alt="Impact of address type on student performance"></p><p>Insights:</p><ul><li>For math performance, there is not too much difference between urban and rural students. However, urban students tend to score slightly more.</li><li>For portuguese performance, we can see that urban students score higher more often than rural students.</li></ul><h3 id="effect-of-relationship-status-on-grades"><a class="markdownIt-Anchor" href="#effect-of-relationship-status-on-grades"></a> Effect of Relationship Status on Grades</h3><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_37_0.png"  alt="Impact of relationship status on student performance"></p><p>Note, that of the 395 math students, 132 (33.4%) were in a relationship. Likewise 239 (36.8%) or of the 649 Portuguese students were in a relationship</p><p>Insights:</p><ul><li>In both datasets, there are more single students than in a relationship (only 33% in math dataset and 36% in portuguese dataset). This might skew results as there is less data to analyze for students in a relationship. We can see that in the Portuguese dataset where there are more values to analyze, the scatter plot shapes tend to look more similar.</li><li>Not enough data to say if relationship has true impact on math performance.</li></ul><h3 id="effect-of-sex-on-grades"><a class="markdownIt-Anchor" href="#effect-of-sex-on-grades"></a> Effect of Sex on Grades</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplots_adjust(hspace=<span class="number">.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sex_plot</span><span class="params">(data, ax, subject)</span>:</span></span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, <span class="number">20</span>)</span><br><span class="line">    sns.kdeplot(data.loc[data[<span class="string">'sex'</span>] == <span class="string">'F'</span>, <span class="string">'G3'</span>], label=<span class="string">'Female'</span>, shade=<span class="literal">True</span>, ax=ax)</span><br><span class="line">    sns.kdeplot(data.loc[data[<span class="string">'sex'</span>] == <span class="string">'M'</span>, <span class="string">'G3'</span>], label=<span class="string">'Male'</span>, shade=<span class="literal">True</span>, ax=ax)</span><br><span class="line">    ax.set_title(<span class="string">f'Female vs Male Students <span class="subst">&#123;subject&#125;</span> Performance'</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">'Grade'</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">'Density'</span>)</span><br><span class="line"></span><br><span class="line">sex_plot(data_m, axs[<span class="number">0</span>], subject=<span class="string">'Math'</span>)</span><br><span class="line">sex_plot(data_p, axs[<span class="number">1</span>], subject=<span class="string">'Portuguese'</span>)</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_41_0.png"  alt="Impact of sex on student performance"></p><h3 id="effect-of-school-choice-on-grades"><a class="markdownIt-Anchor" href="#effect-of-school-choice-on-grades"></a> Effect of School Choice on Grades</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Analyzing impact of choice of school on Portuguese performance</span></span><br><span class="line">plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">b = sns.swarmplot(x=<span class="string">'school'</span>, y=<span class="string">'G3'</span>, data=data_p)</span><br><span class="line">b.axes.set_title(<span class="string">'School Choice vs Final Grade Portuguese'</span>)</span><br><span class="line">b.set_xlabel(<span class="string">'School'</span>)</span><br><span class="line">b.set_ylabel(<span class="string">'Final Grade'</span>);</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="/images/school-success/school-success_43_0.png"  alt="Impact of school choice on student performance"></p><p>Insights:</p><ul><li>From the available data, MS students (<code>school_MS</code>) tend to score less than GP students (<code>school_GP</code>) in Portuguese. Maybe GP is specialized in Portuguese and students have access to higher-quality resources.</li><li>However as for the relationship analysis, there are less students going to MS so it might affect results.</li></ul><h2 id="model-fitting"><a class="markdownIt-Anchor" href="#model-fitting"></a> Model-fitting</h2><p>We are now going to build a multi-linear regression model for both datasets. To avoid the impact of correlated variables, we only use the top twelve most influential predictors. We start with the math scores.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_regression_model</span><span class="params">(df, dummy_df)</span>:</span></span><br><span class="line">    num_df = df.select_dtypes(exclude=[<span class="string">'object'</span>])</span><br><span class="line">    full_df = pd.concat([num_df, dummy_df.drop(<span class="string">'G3'</span>, axis=<span class="number">1</span>)], axis=<span class="number">1</span>)</span><br><span class="line">    full_df.drop([<span class="string">'G1'</span>, <span class="string">'G2'</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    most_inf = np.abs(full_df.corr()[<span class="string">'G3'</span>]).sort_values()[<span class="number">-13</span>:].index</span><br><span class="line">    red_df = full_df.loc[:, most_inf]</span><br><span class="line"></span><br><span class="line">    X = np.array(red_df.drop(<span class="string">'G3'</span>, axis=<span class="number">1</span>))</span><br><span class="line">    y = np.array(red_df[<span class="string">'G3'</span>])</span><br><span class="line"></span><br><span class="line">    Z = sm.add_constant(X)</span><br><span class="line">    mod = sm.OLS(y, Z).fit()</span><br><span class="line">    </span><br><span class="line">    results_as_html = mod.summary().tables[<span class="number">1</span>].as_html()</span><br><span class="line">    coeffs = pd.read_html(results_as_html, header=<span class="number">0</span>, index_col=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    coeffs = coeffs.set_index(pd.Index([<span class="string">'intercept'</span>]).append(red_df.drop(<span class="string">'G3'</span>, axis=<span class="number">1</span>).columns))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> mod.rsquared, coeffs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r2_m, coeffs_m = fit_regression_model(data_m, dummy_dfm)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f"Model R^2: <span class="subst">&#123;r2_m:<span class="number">.02</span>f&#125;</span>"</span>)</span><br><span class="line">display(coeffs_m)</span><br></pre></td></tr></table></figure><pre><code>Model R^2: 0.20</code></pre><table><thead><tr><th></th><th>coef</th><th>std err</th><th>t</th><th>P&gt;|t|</th><th>[0.025</th><th>0.975]</th></tr></thead><tbody><tr><th>intercept</th><td>10.2932</td><td>3.454</td><td>2.981</td><td>0.003</td><td>3.503</td><td>17.083</td></tr><tr><th>paid_yes</th><td>0.2347</td><td>0.439</td><td>0.534</td><td>0.593</td><td>-0.629</td><td>1.099</td></tr><tr><th>sex_M</th><td>1.1617</td><td>0.436</td><td>2.665</td><td>0.008</td><td>0.305</td><td>2.019</td></tr><tr><th>address_U</th><td>0.5889</td><td>0.543</td><td>1.084</td><td>0.279</td><td>-0.479</td><td>1.657</td></tr><tr><th>Mjob_health</th><td>1.1831</td><td>0.779</td><td>1.519</td><td>0.130</td><td>-0.349</td><td>2.715</td></tr><tr><th>traveltime</th><td>-0.2877</td><td>0.324</td><td>-0.887</td><td>0.376</td><td>-0.926</td><td>0.350</td></tr><tr><th>romantic_yes</th><td>-0.8371</td><td>0.458</td><td>-1.829</td><td>0.068</td><td>-1.737</td><td>0.063</td></tr><tr><th>goout</th><td>-0.4753</td><td>0.194</td><td>-2.450</td><td>0.015</td><td>-0.857</td><td>-0.094</td></tr><tr><th>Fedu</th><td>-0.1004</td><td>0.251</td><td>-0.400</td><td>0.689</td><td>-0.594</td><td>0.393</td></tr><tr><th>age</th><td>-0.0467</td><td>0.178</td><td>-0.263</td><td>0.793</td><td>-0.396</td><td>0.302</td></tr><tr><th>higher_yes</th><td>1.4442</td><td>1.044</td><td>1.383</td><td>0.167</td><td>-0.608</td><td>3.497</td></tr><tr><th>Medu</th><td>0.4811</td><td>0.259</td><td>1.861</td><td>0.064</td><td>-0.027</td><td>0.989</td></tr><tr><th>failures</th><td>-1.7399</td><td>0.314</td><td>-5.547</td><td>0.000</td><td>-2.357</td><td>-1.123</td></tr></tbody></table><p>Insights for math data set linear regression model:</p><ul><li>Our model explains explains 20% of the inputs into the final grade (<code>G3</code>), however it could still be improve if the goal of this article would be pure accuracy.</li><li>We can see that the willingness of the student to go into higher education (<code>higher_yes</code>) is a variable with one of the largest absolute coefficients. If the student is willing to go into higher education, their score will increase, on average, by 1.44 points.</li><li>There are other statistically significant coefficients such as <code>failures</code>, <code>sex_M</code>, and <code>goout</code>.</li><li>For example, <code>failures</code> plays a decisive role in student performance: for each class the student has failed in the past, they can roughly except a decrease of 1.74 in their final score.</li></ul><p>And now for the Portuguese scores.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r2_p, coeffs_p = fit_regression_model(data_p, dummy_dfp)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f"Model R^2: <span class="subst">&#123;r2_p:<span class="number">.03</span>f&#125;</span>"</span>)</span><br><span class="line">display(coeffs_p)</span><br></pre></td></tr></table></figure><pre><code>Model R^2: 0.305</code></pre><table><thead><tr><th></th><th>coef</th><th>std err</th><th>t</th><th>P&gt;|t|</th><th>[0.025</th><th>0.975]</th></tr></thead><tbody><tr><th>intercept</th><td>9.8593</td><td>0.612</td><td>16.114</td><td>0.000</td><td>8.658</td><td>11.061</td></tr><tr><th>Mjob_teacher</th><td>0.2976</td><td>0.384</td><td>0.776</td><td>0.438</td><td>-0.456</td><td>1.051</td></tr><tr><th>internet_yes</th><td>0.3248</td><td>0.269</td><td>1.207</td><td>0.228</td><td>-0.204</td><td>0.853</td></tr><tr><th>address_U</th><td>0.3521</td><td>0.252</td><td>1.397</td><td>0.163</td><td>-0.143</td><td>0.847</td></tr><tr><th>reason_reputation</th><td>0.4602</td><td>0.270</td><td>1.704</td><td>0.089</td><td>-0.070</td><td>0.990</td></tr><tr><th>Walc</th><td>-0.1570</td><td>0.108</td><td>-1.455</td><td>0.146</td><td>-0.369</td><td>0.055</td></tr><tr><th>Dalc</th><td>-0.3119</td><td>0.149</td><td>-2.098</td><td>0.036</td><td>-0.604</td><td>-0.020</td></tr><tr><th>Fedu</th><td>0.1503</td><td>0.129</td><td>1.169</td><td>0.243</td><td>-0.102</td><td>0.403</td></tr><tr><th>Medu</th><td>0.0980</td><td>0.137</td><td>0.718</td><td>0.473</td><td>-0.170</td><td>0.366</td></tr><tr><th>studytime</th><td>0.4366</td><td>0.137</td><td>3.192</td><td>0.001</td><td>0.168</td><td>0.705</td></tr><tr><th>school_MS</th><td>-1.0299</td><td>0.252</td><td>-4.087</td><td>0.000</td><td>-1.525</td><td>-0.535</td></tr><tr><th>higher_yes</th><td>1.6627</td><td>0.376</td><td>4.421</td><td>0.000</td><td>0.924</td><td>2.401</td></tr><tr><th>failures</th><td>-1.4374</td><td>0.193</td><td>-7.449</td><td>0.000</td><td>-1.816</td><td>-1.058</td></tr></tbody></table><p>Insights for the portuguese data set linear regression model:</p><ul><li>Our model explains explains 30.5% of the inputs into the final grade (<code>G3</code>), better than the math model but still leaving room for improvement.</li><li>We again see that the desire to go into higher education and the number of previous failures are highly influential when determining a student’s final grade.</li><li>There are other statistically significant coefficients such as <code>school_MS</code>, <code>failures</code> and <code>studytime</code>.</li><li>In fact, the influence of going to Mousinho da Silveira is strong, with an expected decrease in one mark in a student’s Portuguese grade</li></ul><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><p>We have seen that many factors can influence your final grades, the strongest of which typically being socio-economic characteristics (address, parent’s education, family relationship, etc.) that cannot be changed. Those factors can also depend on the potential biases of the dataset. For example, maybe the mother’s unemployment status has a bigger cultural impact on Portuguese student than on UK students. However, some variables that are controllable by the student such as <code>studytime</code>, going out (<code>goout</code>), consumption of alcohol (<code>Dalc</code> and <code>Walc</code>) and potentially relationship status (<code>romantic</code>) have been proved to have an impact on the final grade (<code>G3</code>) of students in these datasets.</p><p>Although valuable insights have been gleaned from this dataset it is clear from our poorly fitting regression model that linear interactions alone are insufficient for capturing a system as complicated as a student’s school performance. If a purely performative model is what we desired, then moving towards a tree-based model or including carefully chosen interaction terms would be advised.</p>]]></content>
      
      
      <categories>
          
          <category> Social Sciences </category>
          
          <category> Education </category>
          
      </categories>
      
      
        <tags>
            
            <tag> visualization </tag>
            
            <tag> data-analysis </tag>
            
            <tag> regression </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gibrat&#39;s Law: The Central Limit Theorem&#39;s Forgotten Twin</title>
      <link href="/gibrats-law/"/>
      <url>/gibrats-law/</url>
      
        <content type="html"><![CDATA[<div class="note info"><p><strong>Accessing Post Source</strong><br>We are still working on getting this site set up, so source code for this post is not yet available. Check back soon and you’ll be able to find it linked here.</p></div><p>Testing, testing. One, two, three. Can everyone hear me alright?</p><p>Wonderful. Hello and welcome to the Warwick Data Science Society Research Blog. It’s so nice to see you.</p><h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2><h3 id="testing-and-tediosity"><a class="markdownIt-Anchor" href="#testing-and-tediosity"></a> Testing and Tediosity</h3><p>Testing is boring. Everyone knows that they <em>should</em> test the solutions they produce, yet reality often fails to live up to this ideal. We check a few obvious things, run through the logic in our head, and convince ourselves that nothing could ever go wrong…and then it does just that.</p><p>Sometimes this is okay. For small, individual projects, it’s not the end of the world if your code base comes collapsing down on you; a few hours of bodging and everything should be stable again (all be it with code now so messy that you’d want to consider cryongenics). For larger projects, and especially those of collaborative nature, this just won’t do.</p><p>That is a long way to say, this post is a test, but hopefully not a boring one. To ensure that the testing of this site is performed thoroughly, I decided to write this post to ensure that everything is behaving as expected. I hope it can also act as a template for other keen researchers—whether they are currently a member of WDSS or merely interested in getting involved—to contribute their own work.</p><p>The philosophy of this post is to write about a topic that is actually (well, hopefully) of some interest to people, and do so in a natural way. None of this testing through enumerating corner-cases; let’s use the site for what it’s made for in practice and share some interesting insights along the way.</p><p>With that in mind, I wish to introduce to you: Gibrat’s law. Don’t be disheartened if you haven’t come across this term before,—most haven’t. This is likely because the rule is overshadowed by it’s far more infamous twin, the central limit theorem. If you’ve not come across this second term either, don’t fret. You may want to watch <a href="https://www.youtube.com/watch?v=JNm3M9cqWyc" target="_blank" rel="noopener">this short video</a> by <a href="https://www.khanacademy.org/" target="_blank" rel="noopener">Khan Academy</a> as a preliminary, but we’ll introduce both of these ideas either way.</p><div class="note info"><p>As a matter of fact, the <a href="https://en.wikipedia.org/wiki/Gibrat%27s_law" target="_blank" rel="noopener">Wikipedia article for Gibrat’s Law</a> is only made up of a few paragraphs with the link to the law’s creator, Robert Gibrat, directing you to a yet non-existant page. We seem to be diving head first into the rabbit hole today.</p></div><h2 id="background"><a class="markdownIt-Anchor" href="#background"></a> Background</h2><div class="note warning"><p>If you are already familiar with central limit theorem, you may wish to skip to the <a href="#from-sums-to-products">next section</a>.</p></div><h3 id="the-central-limit-theorem"><a class="markdownIt-Anchor" href="#the-central-limit-theorem"></a> The Central Limit Theorem</h3><p>We’ll start with the central limit theorem. There are many ways of explaining or defining this phenomenon, each striking a subtle balance between statistical rigor and clarity of explanation. We will favor the latter, ensuring to remember that we should keep it too ourselves if we wish to avoid the disapproving gaze of the pure probability theorists.</p><p>This simplified description goes as follows:</p><ul><li>Consider a sequence of independent random variables</li><li>Take the sum of these values</li><li>Regardless of whether the original variables were normally distributed, the distribution of this sum will tend towards a <a href="https://www.mathsisfun.com/data/standard-normal-distribution.html" target="_blank" rel="noopener">normal distribution</a> as the number of variables increases</li></ul><p>To clarify this notion, let’s look an example. One of the simplest would be an experiment involving tossing multiple fair coins. We consider each coin flip to be an independent random variable taking value zero if the result is tails, and likewise one for heads. We can then say that the total number of heads is the sum of these random variables. It would follow from the central limit theorem that the total number of heads should therefore tend to a normal distribution as the number of total coin tosses gets large. Let’s simulate this experiment for different numbers of coins and see this process in action.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_18_0.png"  alt=""></p><p>Just as we expected, the more coins we toss, the closer the resulting distribution of heads resembles the classic bell shape of the normal distribution. Indeed, once we use around one hundred or more tosses, we can almost model the number of heads as a continuous variable.</p><h3 id="the-importance-of-the-clt"><a class="markdownIt-Anchor" href="#the-importance-of-the-clt"></a> The Importance of the CLT</h3><p>It’s all well and good that the theory works, but why should we care?</p><p>The real power of the central limit theorem presents itself when we want to perform statistical analysis or tests on unfriendly distributions. The normal distribution has some incredibly delightful properties and has been studied in great extent, so working with it is often straightforward. On the other hand, there are many distributions which are not so cooperative, and that’s even assuming we know the distribution of whatever we are trying to model. Thankfully, the central limit theorem allows us to circumvent these issues by assuring us that as long as our process can be modeled as the sum of independent random variables (which is a surprisingly common property), we can approximate its distribution as normal and apply all of the standard techniques we know and love.</p><p>For example, the number of visitors to a website in a given time period is unlikely to have an underlying normal distribution governing the process. This could make it difficult to analyze data related to this, however the central limit theorem offers a workaround. The rough conceptual notion behind this approach is to divide our time period up into smaller and smaller intervals and consider how many people visit the website in each of those. We can assume that these are reasonably independent and so our total visitor count becomes the sum of many independent random variables and so the central limit theorem holds. A small caveat of this specific result is that we require the number of visitors to the site in the time period to be reasonably large (&gt;20 visitors is typically fine), but as long as this holds, we can perform analysis just as if our data was normally distributed.</p><div class="note success"><p>We can even go one step further. Since translating or scaling a normal distribution does not change its normality, it is possible to approximate many situations using the standard normal distrubtion (mean 0, variance 1) by applying appropriate transformations. This makes our lives even simpler and offers some elegance in the process.</p></div><h2 id="from-sums-to-products"><a class="markdownIt-Anchor" href="#from-sums-to-products"></a> From Sums to Products</h2><p>This leads us nicely onto Gibrat’s law. In our rough definition of the central limit theorem above, we described taking numerous independent random variables and computing their sum. Gibrat’s law begins in a similar vein but goes on to consider the product of these values instead. Because of this alteration, we can no longer expect the aggregation to approach a normal distribution as the number of variables grows large. Instead we tend towards a related distribution—the log-normal distribution.</p><p>As the name eludes to, a random variable following log-normal distribution can be defined by its logarithm being normally distributed. The converse of this framing is that whenever we take a normal random variable and take its exponential, the result will follow a log-normal distribution. Because of this, a log-normal random variable only takes strictly positive values with a density curve along the lines of the following.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_28_0.png"  alt=""></p><p>Just as with our coin-tossing experiment for the central limit theorem, we can validate our belief in Gibrat’s law using another simulation. We’ll introduce an explicit example of Gibrat’s law in the final section of the post and for now look an a more esoteric example. In particular, we will consider numerous independent random variables, uniformly-distributed on the interval <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mn>0.5</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0.5, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>. We then take the product of the first <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> these variables and look at the probability distribution of this value. Using Gibrat’s law we would expect this product to approach a log-normal as <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> becomes large, with a density tending in shape towards the curves shown above. A few simulations shows exactly that.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_30_0.png"  alt=""></p><div class="note success"><p>The example shown here is, admittedly, rather abstract. Despite this, it is still simple to frame it in terms of a real world problem (though perhaps not one of upmost importance). For example, we could imagine the product of independent uniform random variables modeling the process of repeatedly cutting a piece of string at a randomly chosen point along its length and retaining the longer part.</p></div><p>It is worth noting that just as there is no one normal distribution, but rather many of various shapes and sizes, parameterized by their mean (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">μ</span></span></span></span>) and variance (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>), the same is true for the log-normal distribution. In fact, we parameterize a log-normal distribution not by its own mean and variance, but by the mean and variance of the resulting normal distribution we obtain when taking logarithms.</p><p>This relationship between the two distributions offers us much of the same power the central limit theorem displays for Gibrat’s law too. Yes, taking the product of the independent random variables in its definition doesn’t give us the normal distribution we so desire directly, but with a simple logarithmic transformation we can get there. Further, because taking the logarithm of a random variable is a simple transformation with some desirable properties, we are able to utilize many of the tools we have developed for manipulating and analyzing the normal distribution with log-normal distribution. This in turn makes Gibrat’s law an incredibly powerful tool for simplifying statistical analysis. One question remains though: when does it hold? What sort of scenarios can be modeled as a product of independent random variables? This brings us neatly to the final section of this post in which we will look into just that, and confirm Gibrat’s law in action.</p><h2 id="verifying-the-law"><a class="markdownIt-Anchor" href="#verifying-the-law"></a> Verifying the Law</h2><p>So far we’ve discussed some interesting ideas, but I think it’s time to pull things back from the land of statistical theory into the real world. Where would we expect to find Gibrat’s law in our lives?</p><p>The key insight needed to answer this question is to understand the underlying mechanism of Gibrat’s law; it’s all above the multiplication of random variables. Specifically, we take the previous product and multiply it by some new random amount. Another way of looking at this is that these random variables represent the growth rate of some quantity. Now, this is not a fixed growth rate as you would have say with interest rates or nuclear decay, but rather a stochastic growth rate.</p><p>To simplify this notion, all we are looking for is systems that evolve by a growth rate proportional to their current size with some added variation captured by the random nature of the variables. An example of such a system (and incidentally the original inspiration for the law) is that of modeling the growth of a firm. In a simple model, we can ignore the impacts of overarching market changes and catastrophic economic events and instead suggest that the growth of a company is roughly proportional to its current size with some added noise. Obviously, this model is primitive and its assumptions do not hold exactly, but it is close enough to believe that the distribution of the size of firms would indeed be log-normally distributed.</p><p>Another example could be the distribution of the population sizes for various countries or cities. There are clear troubles with modeling such a system using Gibrat’s law, but overall it is not unreasonable to suggest that the population growth of a city is largely dependent on its current size, with some added stochasticity. Don’t take my word for it though! Instead, let’s quickly gather some data to verify this result for ourselves.</p><h3 id="sourcing-data"><a class="markdownIt-Anchor" href="#sourcing-data"></a> Sourcing Data</h3><p>After some searching, I decided that the best data source to investigate the validity of Gibrat’s law for use with population data is <a href="https://en.wikipedia.org/wiki/List_of_cities_in_the_United_Kingdom" target="_blank" rel="noopener">this Wikipedia article</a> containing the populations of all sovereign states and dependencies. I then scraped relevant columns from the main table of this page, resulting in a dataset for which ten randomly chosen rows are shown below.</p><table><thead><tr><th></th><th>City</th><th>Population</th></tr></thead><tbody><tr><th>5</th><td>Manchester</td><td>503127</td></tr><tr><th>24</th><td>Southampton</td><td>236882</td></tr><tr><th>28</th><td>York</td><td>198051</td></tr><tr><th>31</th><td>Chelmsford</td><td>168310</td></tr><tr><th>32</th><td>Dundee</td><td>153990</td></tr><tr><th>51</th><td>Bath</td><td>88859</td></tr><tr><th>53</th><td>Hereford</td><td>58896</td></tr><tr><th>56</th><td>Stirling</td><td>34790</td></tr><tr><th>57</th><td>Lichfield</td><td>32219</td></tr><tr><th>66</th><td>London</td><td>7375</td></tr></tbody></table><h3 id="visualizing-the-results"><a class="markdownIt-Anchor" href="#visualizing-the-results"></a> Visualizing the Results</h3><p>We can now plot a histogram of the populations for these cities. On top of this, we overlay a log-normal distribution with parameters chosen to best fit (using maximum likelihood estimation) to see how well the densities match.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_44_0.png"  alt=""></p><p>Now, before you say anything, I know. It’s not perfect. But, I hope we can agree that there is definitely <em>something</em> there. It’s also quite easy to explain why the match isn’t exact. For a start, we only had data for 69 cities so it’s no surprise that the histogram is so jagged. On top of this, city populations is one of the more difficult applications of Gibrat’s law due to the many factors that influence their size that aim to violate the assumptions of the rule.</p><p>Despite these shortcomings, it is clear that Gibrat’s law has value to it either as a conceptual or statistical tool. It should certainly be the case that the validity of the law in any particular scenario should be tested thoroughly before resting too heavy on the results, but as a tool to guide you in the right direction, it is is invaluable.</p><p>As eluded to above, the example of population data is more difficult than most applications of Gibrat’s law due to the numerous and influential externalities. I didn’t want to shy away from this case, especially when it is an example that has clear real-world implications for modeling. It therefore follows that in many more simplistic and controlled cases, Gibrat’s law shines even brighter. For example, it has been of great benefit in my work at AstraZeneca in forming suitable priors for energy distributions in statistical models. Without knowledge of this law it may have taken me more time to discover that the log-normal distribution was a natural and accurate model for these quanta.</p><p>If anything, this post does not offer anything of immediate practical use. That is not to say however that there isn’t an important message. That is, remember Gibrat’s law—it’s there more than you think, and your awareness of it is vital for optimum efficiency in your statistical work. I hope you found this post of some insight, and I look forward to sharing more ideas and research as this blog developments.</p>]]></content>
      
      
      <categories>
          
          <category> Meta </category>
          
          <category> Mathematics </category>
          
          <category> Statistics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> lesson </tag>
            
            <tag> normal-distribution </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
